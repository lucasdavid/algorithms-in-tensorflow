{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC:\n",
    "    plot_initial_preds = False\n",
    "    logs = f'/tf/logs/oxford_iiit_pet/{int(time.time())}'\n",
    "\n",
    "class MC:\n",
    "    downstack_layers = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    \n",
    "    upstack_layers = [\n",
    "        dict(filters=512, size=3, dropout=.2),\n",
    "        dict(filters=256, size=3, dropout=.2),\n",
    "        dict(filters=128, size=3, dropout=.2),\n",
    "        dict(filters=64, size=3, dropout=.2),\n",
    "    ]\n",
    "\n",
    "class DC:\n",
    "    image_size = (256, 256)\n",
    "    batch_size = 64\n",
    "    buffer_size = 1000\n",
    "    \n",
    "    output_channels = 3\n",
    "    \n",
    "class TC:\n",
    "    epochs = 30\n",
    "    lr = 0.001\n",
    "    augmentation = True\n",
    "\n",
    "class Config:\n",
    "    run = RC\n",
    "    data = DC\n",
    "    model = MC\n",
    "    training = TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y, titles=None, rows=1, i0=0):\n",
    "    from math import ceil\n",
    "    \n",
    "    for i, image in enumerate(y):\n",
    "        if image is None:\n",
    "            plt.subplot(rows, ceil(len(y) / rows), i0+i+1)\n",
    "            plt.axis('off')\n",
    "            continue\n",
    "\n",
    "        t = titles[i] if titles else None\n",
    "        plt.subplot(rows, ceil(len(y) / rows), i0+i+1, title=t)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], Config.data.image_size)\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], Config.data.image_size)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def augment_fn(image, segmask):\n",
    "    image = tf.image.random_brightness(image, .2)\n",
    "    image = tf.image.random_contrast(image, .75, 1.)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        segmask = tf.image.flip_left_right(segmask)\n",
    "    \n",
    "    return image, segmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(ds, augment=False):\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "    \n",
    "    if augment:\n",
    "        ds = ds.map(augment_fn)\n",
    "    \n",
    "    return (ds.shuffle(Config.data.buffer_size)\n",
    "              .batch(Config.data.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    (train, val, test), info = tfds.load('oxford_iiit_pet:3.*.*',\n",
    "                               split=['train[:70%]', 'train[70%:]', 'test'],\n",
    "                               with_info=True)\n",
    "    train = load_dataset(train, augment=True)\n",
    "    val = load_dataset(val, augment=True)\n",
    "    test = load_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), = ((x[:8], y[:8]) for x, y in Data.train.take(1))\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plot((*tf.clip_by_value(x, 0, 1), *y), rows=2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), = ((x[:8], y[:8]) for x, y in Data.test.take(1))\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plot((*x, *y), rows=2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications, Model, Input\n",
    "\n",
    "base_model = applications.MobileNetV2(input_shape=[*Config.data.image_size, 3],\n",
    "                                      include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layers = [base_model.get_layer(name).output for name in Config.model.downstack_layers]\n",
    "down_stack = Model(inputs=base_model.input, outputs=layers, name='downstack')\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Layer, Conv2DTranspose, Dropout, Activation,\n",
    "                                     BatchNormalization, ZeroPadding2D)\n",
    "\n",
    "class UpSample(Layer):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 size=3,\n",
    "                 norm='batch',\n",
    "                 dropout=0.,\n",
    "                 activation='relu',\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.size = size\n",
    "        self.conv2d_tr = Conv2DTranspose(\n",
    "            filters, size, strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "            use_bias=False)\n",
    "        self.norm = norm\n",
    "        self.norm_fn = (BatchNormalization() if norm == 'batch' else None)\n",
    "        self.dropout = dropout\n",
    "        self.dropout_fn = (Dropout(dropout) if dropout else None)\n",
    "        self.activation_fn = Activation(activation)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.conv2d_tr(x)\n",
    "        if self.norm: y = self.norm_fn(y)\n",
    "        if self.dropout: y = self.dropout_fn(y)\n",
    "        \n",
    "        return self.activation_fn(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "def unet_model(\n",
    "        downstack_layers,\n",
    "        upstack_layers,\n",
    "        image_size,\n",
    "        output_channels):\n",
    "    inputs = Input(shape=[*image_size, 3], name='images')\n",
    "    outputs = down_stack(inputs)\n",
    "    x = outputs[-1]\n",
    "    skips = reversed(outputs[:-1])\n",
    "\n",
    "    print(f'last :- {x.shape}')\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for l, args, skip in zip(downstack_layers, upstack_layers, skips):\n",
    "        y = UpSample(**args, name=f'{l}/upsampling')(x)\n",
    "        y = Concatenate(name=f'{l}/concat')([y, skip])\n",
    "        print(f'{l} {args} {y.shape} :- {x.shape}, {skip.shape}')\n",
    "        x = y\n",
    "\n",
    "    x = Conv2DTranspose(output_channels, 3,\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        name='segments')(x)\n",
    "    return Model(inputs=inputs, outputs=x, name='unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = unet_model(\n",
    "    Config.model.downstack_layers,\n",
    "    Config.model.upstack_layers,\n",
    "    Config.data.image_size,\n",
    "    Config.data.output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    u,\n",
    "    to_file='pix2pix.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.compile(optimizer=tf.keras.optimizers.Adam(lr=Config.training.lr),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "os.makedirs(Config.run.logs, exist_ok=True)\n",
    "\n",
    "u.fit(\n",
    "    Data.train,\n",
    "    epochs=Config.training.epochs,\n",
    "    validation_data=Data.val,\n",
    "    callbacks=[\n",
    "        callbacks.TerminateOnNaN(),\n",
    "        callbacks.EarlyStopping(patience=Config.training.epochs // 2, verbose=1),\n",
    "        callbacks.ModelCheckpoint(Config.run.logs + '/weights.h5',\n",
    "                                  save_weights_only=True,\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1),\n",
    "        callbacks.ReduceLROnPlateau(patience=5, verbose=1),\n",
    "    ],\n",
    "    verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(u.history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(u.history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend();\n",
    "plt.subplot(222)\n",
    "plt.plot(u.history.history['loss'], label='train loss')\n",
    "plt.plot(u.history.history['val_loss'], label='val loss')\n",
    "plt.legend();\n",
    "plt.subplot(223)\n",
    "plt.plot(u.history.history['lr'], label='learning rate')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.load_weights(Config.run.logs + '/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_segments(p):\n",
    "    p = tf.argmax(p, axis=-1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "\n",
    "    return p\n",
    "\n",
    "def show_predictions(model, ds, num=1):\n",
    "    (x, y), = ((x[:8], y[:8]) for x, y in ds.take(1))\n",
    "    p = model.predict(x)\n",
    "    p = predictions_to_segments(p)\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plot((*tf.clip_by_value(x, 0, 1), *y, *p), rows=3)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(u, Data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(u, Data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [u.evaluate(Data.train, verbose=0),\n",
    "     u.evaluate(Data.val, verbose=0),\n",
    "     u.evaluate(Data.test, verbose=0)],\n",
    "    columns=u.metrics_names,\n",
    "    index=['train', 'val', 'test']).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
