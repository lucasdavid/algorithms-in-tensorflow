{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oW6MoHmLAjVG"
   },
   "source": [
    "# Check Results of Any Given Model\n",
    "\n",
    "Code: [github:lucasdavid/experiments/.../supervised/fine-tuning/best-artworks-of-all-time/results](https://github.com/lucasdavid/experiments/blob/main/notebooks/supervised/fine-tuning/best-artworks-of-all-time/results.ipynb)  \n",
    "Dataset: https://www.kaggle.com/ikarus777/best-artworks-of-all-time  \n",
    "Docker image: `tensorflow/tensorflow:latest-gpu-jupyter`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class RC:\n",
    "    base_path = ('/tf/logs/baoat/d:baoat-patches e:200 fte:0 b:32 v:0.3 '\n",
    "                 'm:inceptionv3 aug:True/1610567121')\n",
    "    model = f'{base_path}/weights.h5'\n",
    "    results = f'{base_path}/eval'\n",
    "    \n",
    "class DC:\n",
    "    path = '/tf/datasets/best-artworks-of-all-time'\n",
    "    images = path + '/images/images'\n",
    "    classes = np.asarray(sorted(os.listdir(images)))\n",
    "\n",
    "class Config:\n",
    "    run = RC\n",
    "    data = DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6178,
     "status": "ok",
     "timestamp": 1596906675688,
     "user": {
      "displayName": "Lucas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgO-xqdSSwbB8xXos7Shqhpq7QJ06mYVUvdLDRcbQ=s64",
      "userId": "01670254553878112810"
     },
     "user_tz": 180
    },
    "id": "qo_IhudYAnF7"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y, titles=None, rows=1, i0=0):\n",
    "    for i, image in enumerate(y):\n",
    "        if image is None:\n",
    "            plt.subplot(rows, ceil(len(y) / rows), i0+i+1)\n",
    "            plt.axis('off')\n",
    "            continue\n",
    "\n",
    "        t = titles[i] if titles else None\n",
    "        plt.subplot(rows, ceil(len(y) / rows), i0+i+1, title=t)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ut3PgruYAkp_"
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(Config.run.results + '/predictions.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(x):\n",
    "    p, c = np.unique(x.pred, return_counts=True)\n",
    "    return p[np.argmax(c)]\n",
    "\n",
    "predictions = pd.DataFrame(results.groupby('name').apply(count), columns=['pred'])\n",
    "labels = results[['name', 'label']].drop_duplicates().set_index('name')\n",
    "report = labels.join(predictions)\n",
    "report['author'] = ['_'.join(n.split('_')[:-1]) for n in report.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report['correct'] = report.label == report.pred\n",
    "report.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "l = Config.data.classes[report.label]\n",
    "p = Config.data.classes[report.pred]\n",
    "\n",
    "print(skmetrics.classification_report(l, p, labels=Config.data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = skmetrics.confusion_matrix(l, p, labels=Config.data.classes)\n",
    "cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.heatmap(cm, cmap='RdPu', annot=False, cbar=False, xticklabels=False,\n",
    "                yticklabels=Config.data.classes);\n",
    "\n",
    "plt.savefig(Config.run.results + '/test-cm.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
