{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reddit_tifu/short Score Regression\n",
    "\n",
    "Dataset: tensorflow/datasets/reddit_tifu/short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class DC:\n",
    "    dataset = 'reddit_tifu/short'\n",
    "    split = ['train[:50%]', 'train[50%:70%]', 'train[70%:]']\n",
    "    batch_size = 256\n",
    "\n",
    "class MC:\n",
    "    vocab_size = 4096\n",
    "    embedding_features = 128\n",
    "    sequence_length = 256\n",
    "\n",
    "class TC:\n",
    "    lr = .001\n",
    "    momentum = .0\n",
    "    epochs = 100\n",
    "    logs = (f'/tf/logs/reddit_tifu/'\n",
    "            f'v:{MC.vocab_size} f:{MC.embedding_features} s:{MC.sequence_length} '\n",
    "            f'lr:{lr} e:{epochs}')\n",
    "    \n",
    "    reduce_lr_factor = .5\n",
    "    reduce_lr_patience = 10\n",
    "    early_stop_patience = 30\n",
    "    \n",
    "class Config:\n",
    "    data = DC\n",
    "    model = MC\n",
    "    training = TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, re, shutil, string\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample_fn(s):\n",
    "    return (s['documents'], tf.math.log(s['score'] + tf.keras.backend.epsilon()))\n",
    "\n",
    "def standardize_fn(x):\n",
    "    x = tf.strings.lower(x)\n",
    "    return tf.strings.regex_replace(x, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "def prepare(ds):\n",
    "    return (ds # .filter(lambda r: r['tldr'] != '')\n",
    "              .batch(Config.data.batch_size)\n",
    "              .map(extract_sample_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "              .cache()\n",
    "              .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class Data:\n",
    "    (train, val, test), info = tfds.load(Config.data.dataset,\n",
    "                                         split=Config.data.split,\n",
    "                                         with_info=True,\n",
    "                                         shuffle_files=True)\n",
    "    \n",
    "    (train, val, test) = map(prepare, (train, val, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=standardize_fn,\n",
    "    max_tokens=Config.model.vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=Config.model.sequence_length,\n",
    "    name='vec')\n",
    "\n",
    "text_ds = Data.train.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vectorize_layer.weights[0].name = 'vec/encodings:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Embedding, Dense, GlobalAveragePooling1D, LSTM,\n",
    "                                     Bidirectional)\n",
    "\n",
    "em = Embedding(\n",
    "    Config.model.vocab_size,\n",
    "    Config.model.embedding_features,\n",
    "    name='em')\n",
    "\n",
    "score_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    em,\n",
    "    Bidirectional(LSTM(128, name='r1/lstm'),\n",
    "                  name='r1/bi'),\n",
    "    Dense(128, activation='relu', name='fc1'),\n",
    "    Dense(1, name='predictions')],\n",
    "    name='score_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(\n",
    "        Config.training.lr,\n",
    "        momentum=Config.training.momentum),\n",
    "    metrics=['mse', 'mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "shutil.rmtree(Config.training.logs, ignore_errors=True)\n",
    "os.makedirs(Config.training.logs, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    score_model.fit(\n",
    "        Data.train,\n",
    "        epochs=Config.training.epochs,\n",
    "        validation_data=Data.val,\n",
    "        callbacks=[\n",
    "            callbacks.TerminateOnNaN(),\n",
    "            callbacks.EarlyStopping(patience=Config.training.early_stop_patience, verbose=1),\n",
    "            callbacks.ModelCheckpoint(Config.training.logs + '/weights',\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True,\n",
    "                                      save_format='tf',\n",
    "                                      verbose=1),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                factor=Config.training.reduce_lr_factor,\n",
    "                patience=Config.training.reduce_lr_patience,\n",
    "                verbose=1),\n",
    "            callbacks.TensorBoard(Config.training.logs,\n",
    "                                  # histogram_freq=max(Config.training.epochs // 10, 5),\n",
    "                                  profile_batch=(10,20))\n",
    "        ]);\n",
    "except KeyboardInterrupt:\n",
    "    print('stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = score_model.history\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(h.history['mse'], label='train MSE')\n",
    "plt.plot(h.history['val_mse'], label='val MSE')\n",
    "plt.legend()\n",
    "plt.subplot(222)\n",
    "plt.plot(h.history['loss'], label='train loss')\n",
    "plt.plot(h.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.subplot(223)\n",
    "plt.plot(h.history['mae'], label='train MAE')\n",
    "plt.plot(h.history['val_mae'], label='val MAE')\n",
    "plt.legend()\n",
    "plt.subplot(224)\n",
    "plt.plot(h.history['lr'], label='learning rate')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    score_model,\n",
    "    to_file='score.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model.load_weights(Config.training.logs + '/weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(\n",
    "    [score_model.evaluate(Data.train, verbose=0),\n",
    "     score_model.evaluate(Data.val, verbose=0),\n",
    "     score_model.evaluate(Data.test, verbose=0)],\n",
    "    columns=score_model.metrics_names,\n",
    "    index=['train', 'val', 'test']).T\n",
    "\n",
    "r.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLED = 8\n",
    "\n",
    "y, p = np.hstack([[y.numpy(), score_model.predict(x).ravel()]\n",
    "                  for x, y in Data.test.take(SAMPLED)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(121, title='log p')\n",
    "a, b = np.percentile(y, (0.1, 99.9))\n",
    "m1 = (y > a) & (y < b)\n",
    "sns.histplot(y[m1], label='true likes', color='crimson')\n",
    "sns.histplot(p[m1], label='pred likes', color='orange')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122, title='p')\n",
    "ey, ep = map(np.exp, (y, p))\n",
    "a, b = np.percentile(ey, (0, 90))\n",
    "m2 = (ey >= a) & (ey <= b)\n",
    "sns.histplot(ey[m2], label='true likes', color='crimson')\n",
    "sns.histplot(ep[m2], label='pred likes', color='orange')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(dict(likes_log=y, likes=ey, pred_log=p, pred=ep))\n",
    "sns.pairplot(r[m1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
