{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (28, 28, 1)\n",
    "VALID_SIZE = 0\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LATENT_DIM = 8\n",
    "\n",
    "REC_LOSS_W = 1\n",
    "KL_LOSS_W = 1\n",
    "\n",
    "CV_PARAMS = dict(strides=2, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (Layer, Conv2D, Conv2DTranspose, Dense,\n",
    "                                     Dropout, BatchNormalization,\n",
    "                                     Activation, GlobalAveragePooling2D,\n",
    "                                     Reshape, Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y, titles=None, rows=1, i0=0):\n",
    "    for i, image in enumerate(y):\n",
    "        if image is None:\n",
    "            plt.subplot(rows, len(y), i0+i+1)\n",
    "            plt.axis('off')\n",
    "            continue\n",
    "\n",
    "        t = titles[i] if titles else None\n",
    "        plt.subplot(rows, len(y), i0+i+1, title=t)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    import io\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'fashion_mnist'\n",
    "CLASSES = np.asarray([\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', 'x y xv yv xt yt')\n",
    "\n",
    "def load_data():\n",
    "    (x, y), (xt, yt) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    x = np.expand_dims(x, -1).astype(\"float32\") / 255\n",
    "    xt = np.expand_dims(xt, -1).astype(\"float32\") / 255\n",
    "\n",
    "    if VALID_SIZE:\n",
    "        _valid_samples = int(VALID_SIZE * len(x))\n",
    "\n",
    "        x, xv = x[_valid_samples:], x[:_valid_samples]\n",
    "        y, yv = x[_valid_samples:], x[:_valid_samples]\n",
    "    else:\n",
    "        xv, yv = None, None\n",
    "        \n",
    "        \n",
    "    print('Train labels:', y[:10])\n",
    "    if VALID_SIZE: print('Valid labels:', yv[:10])\n",
    "    print('Test labels:', yt[:10])\n",
    "    \n",
    "    plot(x[:4])\n",
    "    \n",
    "    return Data(x=x, y=y, xv=xv, yv=yv, xt=xt, yt=yt)\n",
    "\n",
    "Data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ds = (tf.data\n",
    "        .Dataset.from_tensor_slices(Data.x)\n",
    "        .shuffle(len(Data.x))\n",
    "        .batch(BATCH_SIZE, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = int(time.time())\n",
    "LOGS = (f'/tf/logs/d:{DATASET} e:{EPOCHS} b:{BATCH_SIZE} '\n",
    "        f'latent:{LATENT_DIM} rec_w:{round(REC_LOSS_W, 6)} kl_w:{round(KL_LOSS_W, 6)}'\n",
    "        f'/{RUN_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def encode(x, latent_dim=LATENT_DIM):\n",
    "    y = Conv2D(32, 3, name='cv1', **CV_PARAMS)(x)\n",
    "    y = Conv2D(64, 3, name='cv2', **CV_PARAMS)(y)\n",
    "    y = Flatten(name='ft')(y)\n",
    "    y = Dense(16, activation=\"relu\", name='fc1')(y)\n",
    "    zu = Dense(latent_dim, name='zu')(y)\n",
    "    zlv = Dense(latent_dim, name='zlv')(y)\n",
    "\n",
    "    return zu, zlv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=INPUT_SHAPE, name='images')\n",
    "zu, zlv = encode(x)\n",
    "z = Sampling(name='zs')([zu, zlv])\n",
    "\n",
    "encoder = Model(x, [zu, zlv, z], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(z, act='sigmoid'):\n",
    "    z = Dense(7 * 7 * 64, activation=\"relu\")(z)\n",
    "    z = Reshape((7, 7, 64))(z)\n",
    "    z = Conv2DTranspose(64, 3, name='cvt1', **CV_PARAMS)(z)\n",
    "    z = Conv2DTranspose(32, 3, name='cvt2', **CV_PARAMS)(z)\n",
    "    z = Conv2DTranspose(1, 3, activation=act, padding='same', name='decoded')(z)\n",
    "\n",
    "    return z\n",
    "\n",
    "lvs = tf.keras.Input(shape=(LATENT_DIM,), name='latent_vars')\n",
    "ty = decode(lvs)\n",
    "\n",
    "decoder = Model(lvs, ty, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics, losses\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = REC_LOSS_W * tf.reduce_mean(\n",
    "                tf.reduce_sum(losses.binary_crossentropy(data, reconstruction),\n",
    "                              axis=(1, 2))\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = KL_LOSS_W * tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(encoder, decoder)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(encoder, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(decoder, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(LOGS):\n",
    "    raise ValueError(f'Conflicting logs {LOGS}. Change or delete the target folder.')\n",
    "\n",
    "model.fit(\n",
    "    x_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=max(1, EPOCHS // 10),\n",
    "            verbose=1),\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            LOGS,\n",
    "            histogram_freq=1,\n",
    "            embeddings_freq=3),\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLES = 10\n",
    "\n",
    "def plot_latent_space(vae, n=SAMPLES, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    preds = []\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi] + [0] * (LATENT_DIM - 2)])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "            preds.append(x_decoded)\n",
    "\n",
    "    plt_fig = plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "    return figure.reshape(1, *figure.shape, 1)\n",
    "\n",
    "predictions = plot_latent_space(model)\n",
    "\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(f'{SAMPLES**2} samples generated', predictions, step=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "SAMPLES_PLOTTED = 10000\n",
    "\n",
    "def plot_label_clusters(data, labels):\n",
    "    zu, _, _ = encoder.predict(data[:SAMPLES_PLOTTED])\n",
    "    zu = PCA(n_components=2).fit_transform(zu)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    sns.scatterplot(x=zu[:, 0], y=zu[:, 1], hue=labels[:SAMPLES_PLOTTED])\n",
    "    plt.xlabel(\"Pz[0]\")\n",
    "    plt.ylabel(\"Pz[1]\")\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "xp, yp = ((Data.xv, Data.yv) if VALID_SIZE else (Data.x, Data.y))\n",
    "clu_fig = plot_label_clusters(xp, CLASSES[yp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"PCA(z)\", plot_to_image(clu_fig), step=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from math import ceil\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "SAMPLES_PLOTTED = 10000\n",
    "\n",
    "def plot_label_pairs_clusters(data, labels):\n",
    "    zu, _, _ = encoder.predict(data[:SAMPLES_PLOTTED])\n",
    "    dim = zu.shape[1]\n",
    "\n",
    "    d = pd.DataFrame(zu)\n",
    "    d['labels'] = labels[:SAMPLES_PLOTTED]\n",
    "    return sns.pairplot(d, hue='labels')\n",
    "\n",
    "xp, yp = ((Data.xv, Data.yv) if VALID_SIZE else (Data.x, Data.y))\n",
    "g = plot_label_pairs_clusters(xp, CLASSES[yp])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"latent_variables\", plot_to_image(g.fig), step=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_zu, d_zlv, d_z = encoder.predict(Data.x[:SAMPLES])\n",
    "rec = decoder.predict(d_z)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plot(Data.x[:SAMPLES], rows=2)\n",
    "plot(rec, rows=2, i0=SAMPLES)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"reconstruction/train\", plot_to_image(fig), step=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_zu, d_zlv, d_z = encoder.predict(Data.xt[:SAMPLES])\n",
    "rec = decoder.predict(d_z)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plot(Data.x[:SAMPLES], rows=2)\n",
    "plot(rec, rows=2, i0=SAMPLES)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"reconstruction/test\", plot_to_image(fig), step=0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
