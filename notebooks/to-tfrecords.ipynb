{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-marina",
   "metadata": {},
   "source": [
    "# Amazon from Space to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "usual-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funky-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/amazon-from-space'\n",
    "train_file_paths = f'{data_path}/train-jpg/'\n",
    "test_file_paths = f'{data_path}/test-jpg/'\n",
    "train_records_path = f'{data_path}/train-jpg.tfrecords'\n",
    "test_records_path = f'{data_path}/test-jpg.tfrecords'\n",
    "file_format = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "upper-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(data_path + '/train.csv')\n",
    "test_info  = pd.read_csv(data_path + '/test.csv')\n",
    "\n",
    "file_paths = (train_file_paths + train_info.image_name + file_format).values\n",
    "labels = train_info.tags.str.split(' ').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "romantic-recommendation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/data/amazon-from-space/train-jpg/train_0.jpg',\n",
       "       '/data/amazon-from-space/train-jpg/train_1.jpg',\n",
       "       '/data/amazon-from-space/train-jpg/train_2.jpg',\n",
       "       '/data/amazon-from-space/train-jpg/train_3.jpg',\n",
       "       '/data/amazon-from-space/train-jpg/train_4.jpg'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressing-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['haze', 'primary']),\n",
       "       list(['agriculture', 'clear', 'primary', 'water']),\n",
       "       list(['clear', 'primary']), list(['clear', 'primary']),\n",
       "       list(['agriculture', 'clear', 'habitation', 'primary', 'road'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sticky-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.unique(sum(np.unique(labels).tolist(), []))\n",
    "\n",
    "en = LabelEncoder().fit(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valued-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonFromSpace:\n",
    "    classes_ = np.asarray(\n",
    "        ['agriculture', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down',\n",
    "         'clear', 'cloudy', 'conventional_mine', 'cultivation', 'habitation', 'haze',\n",
    "         'partly_cloudy', 'primary', 'road', 'selective_logging', 'slash_burn', 'water'])\n",
    "\n",
    "    @classmethod\n",
    "    def int2str(cls, indices):\n",
    "        return cls.classes_[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.tobytes()]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    @classmethod\n",
    "    def convert(cls, file_paths, labels, writer):\n",
    "        samples = len(file_paths)\n",
    "\n",
    "        for ix, (p, label) in enumerate(zip(file_paths, labels)):\n",
    "            img = skimage.io.imread(p)\n",
    "            h, w, c = img.shape\n",
    "\n",
    "            feature = {\n",
    "              'height': cls._int64_feature(h),\n",
    "              'width': cls._int64_feature(w),\n",
    "              'channels': cls._int64_feature(c),\n",
    "              'label': tf.train.Feature(int64_list=tf.train.Int64List(value=label)),\n",
    "              'image': cls._bytes_feature(img),\n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "            if ix % 100 == 0: print('.', end='')\n",
    "            if ix % int(samples/10) == 0: print(f'\\n{ix/samples:.0%}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-slave",
   "metadata": {},
   "source": [
    "## Copying Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "duplicate-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['/data/amazon-from-space/train-jpg/train_0.tif',\n",
       "        '/data/amazon-from-space/train-jpg/train_1.tif',\n",
       "        '/data/amazon-from-space/train-jpg/train_2.tif', ...,\n",
       "        '/data/amazon-from-space/train-jpg/train_40476.tif',\n",
       "        '/data/amazon-from-space/train-jpg/train_40477.tif',\n",
       "        '/data/amazon-from-space/train-jpg/train_40478.tif'], dtype=object),\n",
       " [array([10, 12]),\n",
       "  array([ 0,  5, 12, 16]),\n",
       "  array([ 5, 12]),\n",
       "  array([ 5, 12]),\n",
       "  array([ 0,  5,  9, 12, 13])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels = [en.transform(l) for l in labels]\n",
    "file_paths, encoded_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "medical-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0%........................................10%........................................20%.........................................30%........................................40%.........................................50%........................................60%.........................................70%........................................80%.........................................90%........................................100%"
     ]
    }
   ],
   "source": [
    "# ! rm -rf /mnt/files/datasets/amazon-from-space/train.tfrecords\n",
    "\n",
    "with tf.io.TFRecordWriter(train_records_path) as w:\n",
    "    AmazonFromSpace.convert(file_paths, encoded_labels, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-massage",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply name fix proposed in discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASEPATH = '/mnt/files/datasets/amazon-from-space/'\n",
    "WORKING = '/mnt/files/datasets/amazon-from-space/working'\n",
    "\n",
    "CSVPATH = os.path.join(BASEPATH, 'test_v2_file_mapping.csv')\n",
    "JPGPATH = os.path.join(BASEPATH, 'test-jpg-v2')\n",
    "TIFPATH = os.path.join(BASEPATH, 'test-tif-v2')\n",
    "FIXEDPATH = os.path.join(WORKING, 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_and_rename(df, num_files=500):\n",
    "    n = 0\n",
    "\n",
    "    if not os.path.exists(FIXEDPATH):\n",
    "        os.mkdir(FIXEDPATH)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        old = os.path.join(TIFPATH, row['old'])\n",
    "        new = os.path.join(FIXEDPATH, row['new'])\n",
    "        shutil.copy(old, new)\n",
    "        n += 1\n",
    "        if n % 500 == 0: print('Copied {}'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-enhancement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy_and_rename(test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv $TIFPATH /tmp/backup\n",
    "mv $FIXEDPATH $test_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert test dataset to tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "primary-jason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/data/amazon-from-space/test-jpg/test_17823.jpg',\n",
       "       '/data/amazon-from-space/test-jpg/test_29423.jpg',\n",
       "       '/data/amazon-from-space/test-jpg/file_7472.jpg',\n",
       "       '/data/amazon-from-space/test-jpg/file_11084.jpg',\n",
       "       '/data/amazon-from-space/test-jpg/file_16408.jpg'], dtype='<U47')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_files = np.asarray([os.path.join(test_file_paths, f) for f in os.listdir(test_file_paths)])\n",
    "test_labels = [[]]*len(test_files)\n",
    "\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "third-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0%.............................................................10%.............................................................20%.............................................................30%.............................................................40%.............................................................50%..............................................................60%.............................................................70%.............................................................80%.............................................................90%.............................................................100%"
     ]
    }
   ],
   "source": [
    "# ! rm -rf $test_records_path\n",
    "\n",
    "with tf.io.TFRecordWriter(test_records_path) as w:\n",
    "    AmazonFromSpace.convert(test_files, test_labels, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
